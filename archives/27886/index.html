<!DOCTYPE html>
<html lang="zh-cn">
  <head>
    <meta charset="utf8"/>
    <meta name="viewport" content="initial-scale=1.0, width=device-width"/>
    <title>
      
      
        相机参数与坐标系变换 | C'est la vie
      
    </title>
    <meta name="description" content=""/>
    <meta name="keywords" content=""/>
    
      <link rel="apple-touch-icon"
            sizes="180x180"
            href="/assets/favicon/favicon-apple-touch.png"/>
    
    
      <link rel="icon"
            type="image/png"
            sizes="32x32"
            href="/assets/favicon/favicon-32x32.png"/>
    
    
      <link rel="icon"
            type="image/png"
            sizes="16x16"
            href="/assets/favicon/favicon-16x16.png"/>
    
    
      <link rel="mask-icon"
            href="/assets/favicon/favicon-logo.svg"
            color=""/>
    
    
    
      
  <style>
    @font-face {
        font-family:sourceHanSerif;
        src: url(/font/normal.ttf);
        font-weight: normal;
    }
  </style>

  <style>
    @font-face {
        font-family:sourceHanSerif;
        src: url(/font/bold.ttf);
        font-weight: bold;
    }
  </style>


    
    <link rel="stylesheet"
          type="text/css"
          href='/css/layout.css'/>
    
    <script src="https://kit.fontawesome.com/c4ba0a82e6.js" crossorigin="anonymous"></script>
    
  <link rel="stylesheet" type="text/css" href="/css/post.css"/>
  
    <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css"/>
  

  <meta name="generator" content="Hexo 7.0.0"></head>

  <body>
    
      <div id="search-mask" style="display:none">
  <div class="search-main" id="search-main">
    <div class="search__head">
      <div class="search-form">
        <svg t="1706347533072"
             class="icon"
             viewBox="0 0 1024 1024"
             version="1.1"
             xmlns="http://www.w3.org/2000/svg"
             p-id="7828"
             width="20"
             height="20">
          <path d="M685.6 660.336l155.152 155.168a16 16 0 0 1 0 22.624l-11.312 11.328a16 16 0 0 1-22.624 0l-158.528-158.544a289.792 289.792 0 0 1-165.152 51.36C322.336 742.256 192 611.904 192 451.12 192 290.336 322.336 160 483.136 160c160.784 0 291.12 130.336 291.12 291.136 0 82.112-33.984 156.272-88.672 209.2z m-202.464 33.92c134.272 0 243.12-108.848 243.12-243.12C726.256 316.848 617.408 208 483.136 208 348.848 208 240 316.848 240 451.136c0 134.272 108.848 243.12 243.136 243.12z" fill="#000000" p-id="7829">
          </path>
        </svg>
        <input id="search-input" placeholder="搜索文章">
        <svg t="1706361500528"
             id="search-clear"
             class="icon"
             viewBox="0 0 1024 1024"
             version="1.1"
             xmlns="http://www.w3.org/2000/svg"
             p-id="4351"
             width="20"
             height="20">
          <path d="M512 562.688l-264.2944 264.2944-50.688-50.688L461.312 512 197.0176 247.7056l50.688-50.688L512 461.312l264.2944-264.2944 50.688 50.688L562.688 512l264.2944 264.2944-50.688 50.688L512 562.688z" fill="#00" p-id="4352">
          </path>
        </svg>
      </div>
    </div>
    <div class="search__body" id="search-result"></div>
    <div class="search__foot"></div>
  </div>
</div>

    
    <div class="head">
      <div class="nav">
        <a href='/' class="nav-logo">
          <img alt="logo" height="60px" width="60px" src="/assets/favicon/favicon-logo.svg"/>
        </a>
        <input id="navBtn" type="checkbox"/>
        <div class="nav-right">
          
            <div class="search-outer">
  <div class="search" id="search-btn">
    <svg t="1706347533072"
         class="icon"
         viewBox="0 0 1024 1024"
         version="1.1"
         xmlns="http://www.w3.org/2000/svg"
         p-id="7828"
         width="20"
         height="20">
      <path d="M685.6 660.336l155.152 155.168a16 16 0 0 1 0 22.624l-11.312 11.328a16 16 0 0 1-22.624 0l-158.528-158.544a289.792 289.792 0 0 1-165.152 51.36C322.336 742.256 192 611.904 192 451.12 192 290.336 322.336 160 483.136 160c160.784 0 291.12 130.336 291.12 291.136 0 82.112-33.984 156.272-88.672 209.2z m-202.464 33.92c134.272 0 243.12-108.848 243.12-243.12C726.256 316.848 617.408 208 483.136 208 348.848 208 240 316.848 240 451.136c0 134.272 108.848 243.12 243.136 243.12z" fill="#000000" p-id="7829">
      </path>
    </svg>
    <span>搜索</span>
    <span class="search-shortcut-key">Ctrl K</span>
  </div>
</div>

          
          <div class="nav-menu">
            
              
                <a class="nav-menu-item" href="/computer">计算机</a>
              
                <a class="nav-menu-item" href="/math">数学</a>
              
                <a class="nav-menu-item" href="/physic">物理</a>
              
                <a class="nav-menu-item" href="/life">生活随笔</a>
              
            
          </div>
        </div>
        <label class="nav-btn" for="navBtn"></label>
      </div>
    </div>
    <div class="body">
      
  <article class="post-content">
    <div class="post-inner--toc">
      <div class="post-content__head">
        <div class="post-title">相机参数与坐标系变换</div>
        <div class="post-info">
          
  
    <a href="/tags/CV/" class="post-tag">#CV</a>
  


          <span class="post-date">2024-03-16</span>
        </div>
      </div>
      
        <aside class="toc-outer">
          <div class="toc-title">目录</div>
          <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#%E5%9D%90%E6%A0%87%E7%B3%BB"><span class="post-toc-number">1.</span> <span class="post-toc-text">坐标系</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#%E7%9B%B8%E6%9C%BA%E5%86%85%E5%A4%96%E5%8F%82%E6%95%B0"><span class="post-toc-number">2.</span> <span class="post-toc-text">相机内外参数</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#%E7%9B%B8%E6%9C%BA%E5%A4%96%E5%8F%82"><span class="post-toc-number">2.1.</span> <span class="post-toc-text">相机外参</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#%E7%9B%B8%E6%9C%BA%E5%86%85%E5%8F%82"><span class="post-toc-number">2.2.</span> <span class="post-toc-text">相机内参</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#%E5%A6%82%E4%BD%95%E8%8E%B7%E5%BE%97%E7%9B%B8%E6%9C%BA%E5%8F%82%E6%95%B0"><span class="post-toc-number">3.</span> <span class="post-toc-text">如何获得相机参数</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#%E5%90%88%E6%88%90%E6%95%B0%E6%8D%AE"><span class="post-toc-number">3.1.</span> <span class="post-toc-text">合成数据</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#%E7%9C%9F%E5%AE%9E%E6%95%B0%E6%8D%AE"><span class="post-toc-number">3.2.</span> <span class="post-toc-text">真实数据</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#llff%E7%9C%9F%E5%AE%9E%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F"><span class="post-toc-number">4.</span> <span class="post-toc-text">LLFF真实数据格式</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#colmap%E5%88%B0llff%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F"><span class="post-toc-number">4.1.</span> <span class="post-toc-text">COLMAP到LLFF数据格式</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#poses_bounds.npy%E9%87%8C%E6%9C%89%E4%BB%80%E4%B9%88"><span class="post-toc-number">4.2.</span> <span class="post-toc-text">poses_bounds.npy里有什么</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#load_llff.py%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB"><span class="post-toc-number">5.</span> <span class="post-toc-text">load_llff.py代码解读</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#drb%E5%88%B0rub%E7%9A%84%E5%8F%98%E6%8D%A2"><span class="post-toc-number">5.1.</span> <span class="post-toc-text">DRB到RUB的变换</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#%E7%BC%A9%E6%94%BE%E5%9B%BE%E5%83%8F%E9%9C%80%E8%A6%81%E4%BF%AE%E6%94%B9%E4%BB%80%E4%B9%88%E7%9B%B8%E6%9C%BA%E5%8F%82%E6%95%B0"><span class="post-toc-number">5.2.</span> <span class="post-toc-text">缩放图像需要修改什么相机参数？</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#viewmatrix"><span class="post-toc-number">5.3.</span> <span class="post-toc-text">viewmatrix()</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#poses_avg"><span class="post-toc-number">5.4.</span> <span class="post-toc-text">poses_avg()</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#recenter_poses"><span class="post-toc-number">5.5.</span> <span class="post-toc-text">recenter_poses()</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#render_path_spiral"><span class="post-toc-number">5.6.</span> <span class="post-toc-text">render_path_spiral()</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#spherify_poses"><span class="post-toc-number">5.7.</span> <span class="post-toc-text">spherify_poses()</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#d%E7%A9%BA%E9%97%B4%E5%B0%84%E7%BA%BF%E6%80%8E%E4%B9%88%E6%9E%84%E9%80%A0"><span class="post-toc-number">6.</span> <span class="post-toc-text">3D空间射线怎么构造</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="post-toc-number">7.</span> <span class="post-toc-text">参考资料</span></a></li></ol>
          <a href="#" class="toc-top">回到顶部</a>
        </aside>
      
      <div class="post-content__body">
        
          <div class="post-gallery">
            
          </div>
        
        <h1 id="坐标系">坐标系</h1>
<figure>
<img src="/archives/27886/coordinate_system.png" alt="坐标系">
<figcaption aria-hidden="true">坐标系</figcaption>
</figure>
<p>为了唯一地描述每一个空间点的坐标，以及相机的位置和朝向，我们需要先定义一个世界坐标系。一个坐标系其实就是由原点的位置与
XYZ
轴的方向决定。为了建立三维空间点到相机平面的映射关系以及多个相机之间的相对关系，也要对每一个相机定义一个局部的相机坐标系。下图为常见的坐标系定义习惯：</p>
<figure>
<img src="/archives/27886/camera_coordinate.png" alt="常见的相机坐标系定义习惯（右手坐标系）">
<figcaption aria-hidden="true">常见的相机坐标系定义习惯（右手坐标系）</figcaption>
</figure>
<blockquote>
<p>在 OpenCV/COLMAP 的相机坐标系里相机朝向 +z 轴，在 LLFF/NeRF
的相机坐标系中里相机朝向 -z 轴。有时我们会按坐标系的 xyz
朝向描述坐标系，如 OpenCV/COLMAP 里使用的 RDF 表述 X 轴指向 right，Y
轴指向 Down，Z 轴指向 Foward。</p>
</blockquote>
<h1 id="相机内外参数">相机内外参数</h1>
<p>相机的<strong>位置</strong>和<strong>朝向</strong>由相机的<strong>外参（extrinsic
matrix）</strong>决定，<strong>投影属性</strong>由相机的<strong>内参（intrinsic
matrix）</strong>决定。</p>
<blockquote>
<p>接下来的介绍假设矩阵是列矩阵（column-major
matrix），变换矩阵左乘坐标向量实现坐标变换（这也是 OpenCV/OpenGL/NeRF
里使用的形式）。</p>
</blockquote>
<h2 id="相机外参">相机外参</h2>
<p>相机外参是一个 <span class="math inline">\(4\times4\)</span> 的矩阵
<span class="math inline">\(M\)</span>，其作用是将世界坐标系的点 <span class="math inline">\(P_{world}=[x,y,z,1]\)</span> 变换到相机坐标系
<span class="math inline">\(P_{camera}=MP_{world}\)</span>
下。因此也把相机外参叫做 <strong>world-to-camera (w2c)
矩阵</strong>。（注意用的是4维的齐次坐标）</p>
<p>相机外参的逆矩阵被称为 <strong>camera-to-world (c2w)
矩阵</strong>，其作用是把相机坐标系的点变换到世界坐标系。c2w 矩阵是一个
<span class="math inline">\(4\times4\)</span> 的矩阵，左上角 <span class="math inline">\(3\times3\)</span> 是旋转矩阵 <span class="math inline">\(R\)</span>，右上角的 <span class="math inline">\(3\times1\)</span> 向量是平移向量 <span class="math inline">\(T\)</span>。有时写的时候可以忽略最后一行 <span class="math inline">\([0,0,0,1]\)</span>。</p>
<figure>
<img src="/archives/27886/c2w.png" alt="camera-to-world (c2w) 矩阵">
<figcaption aria-hidden="true">camera-to-world (c2w) 矩阵</figcaption>
</figure>
<p>c2w
矩阵的值直接描述了相机坐标系的朝向和原点：<strong>旋转矩阵的第一列到第三列分别表示了相机坐标系的
X, Y, Z
轴在世界坐标系下对应的方向；平移向量表示的是相机原点在世界坐标系的对应位置</strong>。</p>
<figure>
<img src="/archives/27886/c2w_description.png" alt="理解 camera-to-world (c2w) 矩阵">
<figcaption aria-hidden="true">理解 camera-to-world (c2w)
矩阵</figcaption>
</figure>
<p>如果将 c2w 作用到（即左乘）相机坐标系下的 X 轴 <span class="math inline">\([1,0,0,0]\)</span>，Y 轴 <span class="math inline">\([0,1,0,0]\)</span>, Z 轴 <span class="math inline">\([0,0,1,0]\)</span>，以及原点 <span class="math inline">\([0,0,0,1]\)</span>（注意方向向量的齐次坐标第四维等于
0，点坐标第四维等于 1），就能得到它们在世界坐标系的坐标表示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">[R, T][<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]^T = [r11, r21, r31]^T <span class="hljs-comment"># X轴对应的是c2w矩阵的第一列</span><br>[R, T][<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]^T = [r12, r22, r32]^T <span class="hljs-comment"># Y轴对应的是c2w矩阵的第二列</span><br>[R, T][<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>]^T = [r13, r23, r33]^T <span class="hljs-comment"># Y轴对应的是c2w矩阵的第三列</span><br>[R, T][<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>]^T = [t1, t2, t3]^T    <span class="hljs-comment"># 原点对应的是c2w矩阵的第四列</span><br></code></pre></td></tr></table></figure>
<h2 id="相机内参">相机内参</h2>
<p>相机的内参矩阵将相机坐标系下的三维坐标映射到二维的图像平面。</p>
<figure>
<img src="/archives/27886/projection.png" alt="映射">
<figcaption aria-hidden="true">映射</figcaption>
</figure>
<p>这里以针孔相机（Pinhole camera）为例介绍相机的内参矩阵 <span class="math inline">\(K\)</span>：</p>
<p><span class="math display">\[
K=\left[\begin{array}{c c c}
    f_x &amp; 0 &amp; c_x \\
    0 &amp; f_y &amp; c_y \\
    0 &amp; 0 &amp; 1
\end{array}\right]
\]</span></p>
<p>内参矩阵 <span class="math inline">\(K\)</span> 包含 <span class="math inline">\(4\)</span> 个值，其中 <span class="math inline">\(f_x\)</span> 和 <span class="math inline">\(f_y\)</span> 是相机的水平和垂直<strong>焦距（focal
length）</strong>（对于理想的针孔相机，<span class="math inline">\(f_x=f_y\)</span>）。焦距的物理含义是相机中心到成像平面的距离，长度以像素为单位。<span class="math inline">\(c_x\)</span> 和 <span class="math inline">\(c_y\)</span>
是图像原点相对于相机光心的水平和垂直偏移量。<span class="math inline">\(c_x\)</span>，<span class="math inline">\(c_y\)</span> 有时候可以用图像宽和高的 <span class="math inline">\(1/2\)</span> 近似:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#  NeRF run_nerf.py有这么一段构造K的代码</span><br>    <span class="hljs-keyword">if</span> K <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>        K = np.array([<br>            [focal, <span class="hljs-number">0</span>, <span class="hljs-number">0.5</span>*W],<br>            [<span class="hljs-number">0</span>, focal, <span class="hljs-number">0.5</span>*H],<br>            [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>]<br>        ])<br></code></pre></td></tr></table></figure>
<h1 id="如何获得相机参数">如何获得相机参数</h1>
<p>NeRF
算法假设相机的内外参数是提供的，那么怎么得到所需要的相机参数呢？这里分合成数据集和真实数据集两种情况。</p>
<h2 id="合成数据">合成数据</h2>
<p>对于合成数据集，我们需要通过指定相机参数来渲染图像，所以得到图像的时候已经知道对应的相机参数，比如像
NeRF 用到的 Blender Lego 数据集。常用的渲染软件还有
Mitsuba、OpenGL、PyTorch3D、Pyrender
等。渲染数据比较简单，但是把得到的相机数据转到 NeRF
代码坐标系牵扯到坐标系之间的变换，有时候会比较麻烦。</p>
<h2 id="真实数据">真实数据</h2>
<p>对于真实场景，比如我们用手机拍摄了一组图像，怎么获得相机位姿？目前常用的方法是利用<strong>运动恢复结构（structure-from-motion,
SFM）</strong>技术估计几个相机间的相对位姿。这个技术比较成熟了，现在学术界里用的比较多的开源软件包是
<a target="_blank" rel="noopener" href="https://colmap.github.io/">COLMAP</a>。输入多张图像，COLMAP
可以估计出相机的内参和外参（也就是 sparse model）。</p>
<figure>
<img src="/archives/27886/COLMAP.png" alt="COLMAP">
<figcaption aria-hidden="true">COLMAP</figcaption>
</figure>
<p>下面是 COLMAP 官网教程给的三个命令行操作步骤，简单来说：</p>
<ol type="1">
<li>第一步是对所有的图像进行特征点检测与提取；</li>
<li>第二步是进行特征点匹配；</li>
<li>第三步是进行 SFM 恢复相机位姿和稀疏的三维特征点。</li>
</ol>
<p>具体的使用方法和原理还请阅读其官方文档。其实 COLMAP 也集成了
multiview stereo (MVS) 算法用于重建场景完整的三维结构（也称为 dense
model）。不过 NeRF
本身是一种新颖的场景表征和重建算法，我们只需要相机的位姿信息，所以我们不需要跑
MVS 进行 dense 重建。</p>
<blockquote>
<p>如果没有标定信息，基于单目的 SFM 无法获得场景的绝对尺度。</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># The project folder must contain a folder &quot;images&quot; with all the images.</span><br>$ DATASET_PATH=/path/to/dataset<br><br>$ colmap feature_extractor \<br>   --database_path <span class="hljs-variable">$DATASET_PATH</span>/database.db \<br>   --image_path <span class="hljs-variable">$DATASET_PATH</span>/images<br><br>$ colmap exhaustive_matcher \<br>   --database_path <span class="hljs-variable">$DATASET_PATH</span>/database.db<br><br>$ <span class="hljs-built_in">mkdir</span> <span class="hljs-variable">$DATASET_PATH</span>/sparse<br><br>$ colmap mapper \<br>    --database_path <span class="hljs-variable">$DATASET_PATH</span>/database.db \<br>    --image_path <span class="hljs-variable">$DATASET_PATH</span>/images \<br>    --output_path <span class="hljs-variable">$DATASET_PATH</span>/sparse<br></code></pre></td></tr></table></figure>
<p>使用 COLMAP 得到相机参数后只需要转成 NeRF
可以读取的格式即可以用于模型训练了。那这里面需要做什么操作？</p>
<h1 id="llff真实数据格式">LLFF真实数据格式</h1>
<p>LLFF（Local Light Field Fusion），是 NeRF
作者上一篇做新视角合成的工作 <a target="_blank" rel="noopener" href="https://github.com/fyusion/llff">Code release for Local Light
Field Fusion at SIGGRAPH 2019</a>。为了和 LLFF
方法保持一致的数据格式，NeRF 使用 load_llff.py 读取 LLFF
格式的真实数据，并建议大家使用 LLFF 提供的的 <a target="_blank" rel="noopener" href="https://github.com/Fyusion/LLFF/blob/master/imgs2poses.py">imgs2poses.py</a>
文件获取所需相机参数。</p>
<h2 id="colmap到llff数据格式">COLMAP到LLFF数据格式</h2>
<p>imgs2poses.py 这个文件其实很简单，就干了两件事。</p>
<ol type="1">
<li>调用 COLMAP 软件估计相机的参数，在 sparse/0/
文件夹下生成一些二进制文件：cameras.bin, images.bin, points3D.bin,
project.ini；</li>
<li>读取上一步得到的二进制文件，保存成一个 poses_bounds.npy 文件；</li>
</ol>
<p>这里有一个细节需要注意，就是在 pose_utils.py 文件里
load_colmap_data() 函数的倒数第二行，有一个操作将 COLMAP 得到的 c2w
旋转矩阵中的第一列和第二列互换，第三列乘以负号：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># LLFF/llff/poses/pose_utils.py</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_colmap_data</span>(<span class="hljs-params">realdir</span>):<br>    ...   <br>    <span class="hljs-comment"># must switch to [-u, r, -t] from [r, -u, t], NOT [r, u, -t]</span><br>    poses = np.concatenate([poses[:, <span class="hljs-number">1</span>:<span class="hljs-number">2</span>, :], poses[:, <span class="hljs-number">0</span>:<span class="hljs-number">1</span>, :], -poses[:, <span class="hljs-number">2</span>:<span class="hljs-number">3</span>, :], poses[:, <span class="hljs-number">3</span>:<span class="hljs-number">4</span>, :], poses[:, <span class="hljs-number">4</span>:<span class="hljs-number">5</span>, :]], <span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> poses, pts3d, perm<br></code></pre></td></tr></table></figure>
<p>上述操作实际上就是把相机坐标系轴的朝向进行了变换：X 和 Y 轴调换，Z
轴取反，如下图所示：</p>
<figure>
<img src="/archives/27886/COLMAP_to_LLFF.png" alt="从Colmap的坐标系转到LLFF的坐标系">
<figcaption aria-hidden="true">从Colmap的坐标系转到LLFF的坐标系</figcaption>
</figure>
<h2 id="poses_bounds.npy里有什么">poses_bounds.npy里有什么</h2>
<p>load_llff.py 会直接读取 poses_bounds.npy
文件获得相机参数。poses_bounds.npy 是一个 <span class="math inline">\(N\times17\)</span> 的矩阵，其中 <span class="math inline">\(N\)</span> 是图像的数量，即每一张图像有 <span class="math inline">\(17\)</span> 个参数。其中前面 <span class="math inline">\(15\)</span> 个参数可以重排成 <span class="math inline">\(3\times5\)</span> 的矩阵形式：</p>
<p><span class="math display">\[
\left[\begin{array}{c c c c c}
    r_{11} &amp; r_{12} &amp; r_{13} &amp; t_1 &amp; H \\
    r_{21} &amp; r_{22} &amp; r_{23} &amp; t_2 &amp; W \\
    r_{31} &amp; r_{32} &amp; r_{33} &amp; t_3 &amp; f \\
\end{array}\right]
\]</span></p>
<p>左边 <span class="math inline">\(3\times3\)</span> 矩阵是 c2w
的旋转矩阵，第四列是 c2w 的平移向量，第五列分别是图像的高 <span class="math inline">\(H\)</span>、宽 <span class="math inline">\(W\)</span> 和相机的焦距 <span class="math inline">\(f\)</span>。</p>
<p>最后两个参数用于表示<strong>场景的范围 Bounds
(bds)</strong>，是该相机视角下场景点离相机中心最近（near）和最远（far）的距离，所以
near/far 肯定是大于 0 的。</p>
<ul>
<li>这两个值是怎么得到的？是在 imgs2poses.py 中，计算 colmap
重建的三维稀疏点在各个相机视角下最近和最远的距离得到的。</li>
<li>这两个值有什么用？之前提到体素渲染需要在一条射线上采样三维点，这就需要一个采样区间，而
near 和 far 就是定义了采样区间的最近点和最远点。贴近场景边界的 near/far
可以使采样点分布更加密集，从而有效地提升收敛速度和渲染质量。</li>
</ul>
<figure>
<img src="/archives/27886/near_far.png" alt="poses_bounds.npy里最后两个参数（near/far）">
<figcaption aria-hidden="true">poses_bounds.npy里最后两个参数（near/far）</figcaption>
</figure>
<h1 id="load_llff.py代码解读">load_llff.py代码解读</h1>
<p>接着，我们介绍 NeRF 代码里 load_llff.py
代码里的一些细节。对三维视觉不熟悉的读者，早期读代码的时候可能会有不少困惑。</p>
<h2 id="drb到rub的变换">DRB到RUB的变换</h2>
<p>第一个疑问是，为什么读进 poses_bounds.npy
里的c2w矩阵之后，对c2w的旋转矩阵又做了一些列变换？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># load_llff.py文件</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_llff_data</span>(<span class="hljs-params">basedir, factor=<span class="hljs-number">8</span>, recenter=<span class="hljs-literal">True</span>, bd_factor=<span class="hljs-number">.75</span>, spherify=<span class="hljs-literal">False</span>, path_zflat=<span class="hljs-literal">False</span></span>):<br>    <br>    poses, bds, imgs = _load_data(basedir, factor=factor) <span class="hljs-comment"># factor=8 downsamples original imgs by 8x</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Loaded&#x27;</span>, basedir, bds.<span class="hljs-built_in">min</span>(), bds.<span class="hljs-built_in">max</span>())<br>    <br>    <span class="hljs-comment"># Correct rotation matrix ordering and move variable dim to axis 0</span><br>    poses = np.concatenate([poses[:, <span class="hljs-number">1</span>:<span class="hljs-number">2</span>, :], -poses[:, <span class="hljs-number">0</span>:<span class="hljs-number">1</span>, :], poses[:, <span class="hljs-number">2</span>:, :]], <span class="hljs-number">1</span>)<br>    ...<br></code></pre></td></tr></table></figure>
<p>上面的代码段的最后一行实际上是把旋转矩阵的第一列（X轴）和第二列（Y轴）互换，并且对第二列（Y轴）做了一个反向。这样做的目的是将
LLFF 的相机坐标系变成 OpenGL/NeRF 的相机坐标系，如下图所示：</p>
<figure>
<img src="/archives/27886/DRB_to_RUB.png" alt="poses = np.concatenate([poses[:, 1:2, :], -poses[:, 0:1, :], poses[:, 2:, :]], 1)">
<figcaption aria-hidden="true">poses = np.concatenate([poses[:, 1:2, :],
-poses[:, 0:1, :], poses[:, 2:, :]], 1)</figcaption>
</figure>
<h2 id="缩放图像需要修改什么相机参数">缩放图像需要修改什么相机参数？</h2>
<p>在 _load_data() 函数里，有一个用于图像缩放的 factor 比例参数，将
<span class="math inline">\(H\times W\)</span> 的图像缩放成 <span class="math inline">\((H/factor)\times(W/factor)\)</span>。这里面有一个问题是如果缩放了图像尺寸，相机的参数需要相应的做什么变化？</p>
<p><strong>外参（位置和朝向）不变，相机的焦距 <span class="math inline">\(f\)</span>，<span class="math inline">\(c_x\)</span>, 和 <span class="math inline">\(c_y\)</span>
等比例缩放</strong>。下图的示意图展示了当相机位置不变，相机视野（Field
of view, FOV）不变的情况下，图像的高和焦距长短的关系。</p>
<figure>
<img src="/archives/27886/FOV.png" alt="图像平面1与图像平面2拍摄的图像内容是一样的，只是分辨率不同">
<figcaption aria-hidden="true">图像平面1与图像平面2拍摄的图像内容是一样的，只是分辨率不同</figcaption>
</figure>
<h2 id="viewmatrix">viewmatrix()</h2>
<p>view_matrix 是一个构造相机矩阵的的函数，输入是相机的 <strong>Z
轴朝向、up 轴的朝向</strong>（即相机平面朝上的方向
Y）、以及相机中心。输出下图所示的camera-to-world（c2w）矩阵。因为 Z
轴朝向，Y 轴朝向，和相机中心都已经给定，所以只需求 X
轴的方向即可。又由于 X 轴同时与 Z 轴和 Y 轴垂直，我们可以用 Y 轴与 Z
轴的叉乘得到 X 轴方向。</p>
<figure>
<img src="/archives/27886/c2w_description.png" alt="camera-to-world matrix">
<figcaption aria-hidden="true">camera-to-world matrix</figcaption>
</figure>
<p>下面是 load_llff.py 里关于 view_matrix()
的定义，看起来复杂一些。其实就是比刚刚的描述比多了一步：在用 Y 轴与 Z
轴叉乘得到 X 轴后，再次用 Z 轴与 X 轴叉乘得到新的 Y
轴。为什么这么做呢？这是因为传入的 up(Y)
轴是通过一些计算得到的，不一定和 Z 轴垂直，所以多这么一步。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># load_llff.py</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">viewmatrix</span>(<span class="hljs-params">z, up, pos</span>):<br>    vec2 = normalize(z)<br>    vec1_avg = up<br>    vec0 = normalize(np.cross(vec1_avg, vec2))<br>    vec1 = normalize(np.cross(vec2, vec0))<br>    m = np.stack([vec0, vec1, vec2, pos], <span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> m<br></code></pre></td></tr></table></figure>
<h2 id="poses_avg">poses_avg()</h2>
<p>这个函数顾名思义就是多个相机的平均位姿（包括位置和朝向）。输入是多个相机的位姿。</p>
<ol type="1">
<li>对多个相机的中心进行求均值得到 center；</li>
<li>对所有相机的 Z 轴求平均得到 vec2
向量（方向向量相加其实等效于平均方向向量）；</li>
<li>对所有的相机的 Y 轴求平均得到 up 向量；</li>
<li>将 vec2, up, 和 center 输入到刚刚介绍的 viewmatrix()
函数就可以得到平均的相机位姿了。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">poses_avg</span>(<span class="hljs-params">poses</span>):<br><br>    hwf = poses[<span class="hljs-number">0</span>, :<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>:]<br><br>    center = poses[:, :<span class="hljs-number">3</span>, <span class="hljs-number">3</span>].mean(<span class="hljs-number">0</span>)<br>    vec2 = normalize(poses[:, :<span class="hljs-number">3</span>, <span class="hljs-number">2</span>].<span class="hljs-built_in">sum</span>(<span class="hljs-number">0</span>))<br>    up = poses[:, :<span class="hljs-number">3</span>, <span class="hljs-number">1</span>].<span class="hljs-built_in">sum</span>(<span class="hljs-number">0</span>)<br>    c2w = np.concatenate([viewmatrix(vec2, up, center), hwf], <span class="hljs-number">1</span>)<br>    <br>    <span class="hljs-keyword">return</span> c2w<br></code></pre></td></tr></table></figure>
<p>下图展示了一个 poses_avg()
函数的例子。左边是多个输入相机的位姿，右边是返回的平均相机姿态。可以看出平均相机位姿的位置和朝向是之前所有相机的均值。</p>
<figure>
<img src="/archives/27886/poses_avg.png" alt="poses_avg()">
<figcaption aria-hidden="true">poses_avg()</figcaption>
</figure>
<blockquote>
<p>中间大的坐标系是世界坐标系，每一个小的坐标系对应一个相机的局部坐标系。红绿蓝（RGB）轴分别代表
XYZ 轴。</p>
</blockquote>
<h2 id="recenter_poses">recenter_poses()</h2>
<p>recenter_poses()
函数的名字听起来是中心化相机位姿（同样包括位置和朝向）的意思。输入 <span class="math inline">\(N\)</span> 个相机位姿，会返回N个相机位姿。</p>
<p>具体的操作了解起来可能有点跳跃。第一步先用刚刚介绍的 poses_avg(poses)
得到多个输入相机的平均位姿 c2w，接着用这个平均位姿 c2w
的逆左乘到输入的相机位姿上就完成了归一化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">recenter_poses</span>(<span class="hljs-params">poses</span>):<br><br>    poses_ = poses+<span class="hljs-number">0</span><br>    bottom = np.reshape([<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1.</span>], [<span class="hljs-number">1</span>,<span class="hljs-number">4</span>])<br>    c2w = poses_avg(poses)<br>    c2w = np.concatenate([c2w[:<span class="hljs-number">3</span>,:<span class="hljs-number">4</span>], bottom], -<span class="hljs-number">2</span>)<br>    bottom = np.tile(np.reshape(bottom, [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">4</span>]), [poses.shape[<span class="hljs-number">0</span>],<span class="hljs-number">1</span>,<span class="hljs-number">1</span>])<br>    poses = np.concatenate([poses[:,:<span class="hljs-number">3</span>,:<span class="hljs-number">4</span>], bottom], -<span class="hljs-number">2</span>)<br><br>    poses = np.linalg.inv(c2w) @ poses<br>    poses_[:,:<span class="hljs-number">3</span>,:<span class="hljs-number">4</span>] = poses[:,:<span class="hljs-number">3</span>,:<span class="hljs-number">4</span>]<br>    poses = poses_<br>    <span class="hljs-keyword">return</span> poses<br></code></pre></td></tr></table></figure>
<p>首先我们要知道利用同一个旋转平移变换矩阵左乘所有的相机位姿是对所有的相机位姿做一个全局的旋转平移变换，那下一个问题就是这些相机会被变到什么样的一个位置？我们可以用平均相机位姿作为支点理解，如果把平均位姿的逆
<span class="math inline">\(\text{c2w}^{-1}\)</span> 左乘平均相机位姿
c2w，返回的相机位姿中旋转矩阵为单位矩阵，平移量为零向量。也就是变换后的平均相机位姿的位置处在世界坐标系的原点，XYZ
轴朝向和世界坐标系的向一致。</p>
<p>下图我们用一个例子帮助理解。左边和右边分别是输入和输出的相机位姿示意图。我们可以看到变换后的多个相机的平均位姿处在世界坐标系的原点，并且相机坐标系的
XYZ 轴与世界坐标系保持一致了。</p>
<figure>
<img src="/archives/27886/recenter_poses.png" alt="recenter_poses()">
<figcaption aria-hidden="true">recenter_poses()</figcaption>
</figure>
<blockquote>
<p>中间大的坐标系是世界坐标系，每一个小的坐标系对应一个相机的局部坐标系。红绿蓝（RGB）轴分别代表
XYZ 轴。</p>
</blockquote>
<h2 id="render_path_spiral">render_path_spiral()</h2>
<p>这个函数写的有点复杂，它和模型训练没有关系，主要是用来生成一个相机轨迹用于新视角的合成。</p>
<p>下面只放了render_path_spiral()函数的定义，NeRF代码里还有一段是在准备输入参数，由于相关代码比较长就不贴出来。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">render_path_spiral</span>(<span class="hljs-params">c2w, up, rads, focal, zdelta, zrate, rots, N</span>):<br>    render_poses = []<br>    rads = np.array(<span class="hljs-built_in">list</span>(rads) + [<span class="hljs-number">1.</span>])<br>    hwf = c2w[:,<span class="hljs-number">4</span>:<span class="hljs-number">5</span>]<br>    <br>    <span class="hljs-keyword">for</span> theta <span class="hljs-keyword">in</span> np.linspace(<span class="hljs-number">0.</span>, <span class="hljs-number">2.</span> * np.pi * rots, N+<span class="hljs-number">1</span>)[:-<span class="hljs-number">1</span>]:<br>        c = np.dot(c2w[:<span class="hljs-number">3</span>,:<span class="hljs-number">4</span>], np.array([np.cos(theta), -np.sin(theta), -np.sin(theta*zrate), <span class="hljs-number">1.</span>]) * rads) <br>        z = normalize(c - np.dot(c2w[:<span class="hljs-number">3</span>,:<span class="hljs-number">4</span>], np.array([<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,-focal, <span class="hljs-number">1.</span>])))<br>        render_poses.append(np.concatenate([viewmatrix(z, up, c), hwf], <span class="hljs-number">1</span>))<br>    <span class="hljs-keyword">return</span> render_poses<br></code></pre></td></tr></table></figure>
<p>需要知道这个函数它是想生成一段螺旋式的相机轨迹，相机绕着一个轴旋转，其中相机始终注视着一个焦点，相机的
up 轴保持不变。简单说一下上面的代码：</p>
<p>首先是一个 for 循环，每一迭代生成一个新的相机位置。<code>c</code>
是当前迭代的相机在世界坐标系的位置，<code>np.dot(c2w[:3,:4], np.array([0,0,-focal, 1.])</code>
是焦点在世界坐标系的位置，<code>z</code> 是相机 z
轴在世界坐标系的朝向。接着使用介绍的 viewmatrix(z, up, c)
构造当前相机的矩阵。</p>
<p>下面这个图可视化了 render_path_spiral() 生成的轨迹：</p>
<figure>
<img src="/archives/27886/render_path_spiral.png" alt="render_path_spiral()">
<figcaption aria-hidden="true">render_path_spiral()</figcaption>
</figure>
<blockquote>
<p>中间大的坐标系是世界坐标系，每一个小的坐标系对应一个相机的局部坐标系。红绿蓝（RGB）轴分别代表
XYZ 轴。</p>
</blockquote>
<h2 id="spherify_poses">spherify_poses()</h2>
<p>刚刚介绍的 render_path_spiral()
假设所有相机都朝向某一个方向，也就是所谓的 faceforward
场景。对于相机围绕着一个物体拍摄的 360 度场景，NeRF 代码提供了一个
spherify_poses()
的函数用于"球面化"相机分布并返回一个环绕的相机轨迹用于新视角合成。这里插一句，在训练
360 度场景的时候，需要配合 <code>--no_ndc --spherify --lindisp</code>
三个参数以得到好的结果，具体原理这里不展开介绍。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> spherify:<br>    poses, render_poses, bds = spherify_poses(poses, bds)<br></code></pre></td></tr></table></figure>
<p>这个函数也比较复杂，前半部分是在将输入的相机参数进行归一化，后半部分是生成一段相机轨迹用于合成新视角。对输入相机参数进行归一化时，思路是：</p>
<ul>
<li>用 <code>pt_mindist = min_line_dist(rays_o, rays_d)</code>
找到离所有相机中心射线距离之和最短的点（可以先简单理解成场景的中心位置）</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">rays_d = poses[:,:<span class="hljs-number">3</span>,<span class="hljs-number">2</span>:<span class="hljs-number">3</span>]<br>rays_o = poses[:,:<span class="hljs-number">3</span>,<span class="hljs-number">3</span>:<span class="hljs-number">4</span>]<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">min_line_dist</span>(<span class="hljs-params">rays_o, rays_d</span>):<br>    A_i = np.eye(<span class="hljs-number">3</span>) - rays_d * np.transpose(rays_d, [<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>])<br>    b_i = -A_i @ rays_o<br>    pt_mindist = np.squeeze(-np.linalg.inv((np.transpose(A_i, [<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>]) @ A_i).mean(<span class="hljs-number">0</span>)) @ (b_i).mean(<span class="hljs-number">0</span>))<br>    <span class="hljs-keyword">return</span> pt_mindist<br><br>pt_mindist = min_line_dist(rays_o, rays_d)<br></code></pre></td></tr></table></figure>
<ul>
<li>将得到的场景中心位置移到世界坐标系的原点，同时将所有相机 z
轴的平均方向转到和世界坐标系的 z 轴相同</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">center = pt_mindist<br>up = (poses[:,:<span class="hljs-number">3</span>,<span class="hljs-number">3</span>] - center).mean(<span class="hljs-number">0</span>)<br><br>vec0 = normalize(up)<br>vec1 = normalize(np.cross([<span class="hljs-number">.1</span>,<span class="hljs-number">.2</span>,<span class="hljs-number">.3</span>], vec0))<br>vec2 = normalize(np.cross(vec0, vec1))<br>pos = center<br>c2w = np.stack([vec1, vec2, vec0, pos], <span class="hljs-number">1</span>)<br><br>poses_reset = np.linalg.inv(p34_to_44(c2w[<span class="hljs-literal">None</span>])) @ p34_to_44(poses[:,:<span class="hljs-number">3</span>,:<span class="hljs-number">4</span>])<br></code></pre></td></tr></table></figure>
<ul>
<li>最后将相机的位置缩放到单位圆内</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">rad = np.sqrt(np.mean(np.<span class="hljs-built_in">sum</span>(np.square(poses_reset[:,:<span class="hljs-number">3</span>,<span class="hljs-number">3</span>]), -<span class="hljs-number">1</span>)))<br>sc = <span class="hljs-number">1.</span>/rad<br>poses_reset[:,:<span class="hljs-number">3</span>,<span class="hljs-number">3</span>] *= sc<br></code></pre></td></tr></table></figure>
<p>下面这个图可视化了 spherify_poses() 返回的结果：</p>
<figure>
<img src="/archives/27886/spherify_poses.png" alt="spherify_poses()">
<figcaption aria-hidden="true">spherify_poses()</figcaption>
</figure>
<blockquote>
<p>中间大的坐标系是世界坐标系，每一个小的坐标系对应一个相机的局部坐标系。红绿蓝（RGB）轴分别代表
XYZ 轴。</p>
</blockquote>
<h1 id="d空间射线怎么构造">3D空间射线怎么构造</h1>
<p>最后我们看一下这个射线是怎么构造的。<strong>给定一张图像的一个像素点，我们的目标是构造以相机中心为起始点，经过相机中心和像素点的射线。</strong></p>
<p>首先，明确两件事：</p>
<ol type="1">
<li>一条射线包括一个起始点和一个方向，起点的话就是相机中心。对于射线方向，我们都知道两点确定一条直线，所以除了相机中心我们还需另一个点，而这个点就是成像平面的像素点。</li>
<li>NeRF 代码是在相机坐标系下构建射线，然后再通过 camera-to-world (c2w)
矩阵将射线变换到世界坐标系。</li>
</ol>
<p>通过上述的讨论，我们第一步是要先写出相机中心和像素点在相机坐标系的三维坐标。下面我们以
OpenCV/Colmap 的相机坐标系为例介绍。相机中心的坐标很明显就是 <span class="math inline">\([0,0,0]\)</span>
了。像素点的坐标可能复杂一点：首先三维像素点的 x 和 y
坐标是二维的图像坐标 <span class="math inline">\((i, j)\)</span>
减去光心坐标 <span class="math inline">\((c_x,c_y)\)</span>，然后 z
坐标其实就是焦距 <span class="math inline">\(f\)</span>
(因为图像平面距离相机中心的距离就是焦距 <span class="math inline">\(f\)</span>)。</p>
<p>所以我们就可以得到射线的方向向量是 <span class="math inline">\((i-c_x,j-c_y,f)-(0,0,0)=(i-c_x,j-c_y,f)\)</span>。因为是向量，我们可以把整个向量除以焦距
<span class="math inline">\(f\)</span> 归一化 z 坐标，得到 <span class="math inline">\((\frac{i-c_x}{f},\frac{i-c_y}{f},1)\)</span>。</p>
<p>接着只需要用 c2w
矩阵把相机坐标系下的相机中心和射线方向变换到世界坐标系就搞定了。</p>
<figure>
<img src="/archives/27886/OpenCV_or_Colmap_ray.png" alt="OpenCV/Colmap相机坐标系下射线的构造示意图">
<figcaption aria-hidden="true">OpenCV/Colmap相机坐标系下射线的构造示意图</figcaption>
</figure>
<p>下面是 NeRF
的实现代码。但关于这里面有一个细节需要注意一下：为什么函数的第二行中
dirs 的 y 和 z 的方向值需要乘以负号，和我们刚刚推导的的 <span class="math inline">\((\frac{i-c_x}{f},\frac{i-c_y}{f},1)\)</span>
不太一样呢？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_rays_np</span>(<span class="hljs-params">H, W, K, c2w</span>):<br>    i, j = np.meshgrid(np.arange(W, dtype=np.float32), np.arange(H, dtype=np.float32), indexing=<span class="hljs-string">&#x27;xy&#x27;</span>)<br>    dirs = np.stack([(i-K[<span class="hljs-number">0</span>][<span class="hljs-number">2</span>])/K[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>], -(j-K[<span class="hljs-number">1</span>][<span class="hljs-number">2</span>])/K[<span class="hljs-number">1</span>][<span class="hljs-number">1</span>], -np.ones_like(i)], -<span class="hljs-number">1</span>)<br>    <span class="hljs-comment"># Rotate ray directions from camera frame to the world frame</span><br>    rays_d = np.<span class="hljs-built_in">sum</span>(dirs[..., np.newaxis, :] * c2w[:<span class="hljs-number">3</span>,:<span class="hljs-number">3</span>], -<span class="hljs-number">1</span>)  <span class="hljs-comment"># dot product, equals to: [c2w.dot(dir) for dir in dirs]</span><br>    <span class="hljs-comment"># Translate camera frame&#x27;s origin to the world frame. It is the origin of all rays.</span><br>    rays_o = np.broadcast_to(c2w[:<span class="hljs-number">3</span>,-<span class="hljs-number">1</span>], np.shape(rays_d))<br>    <span class="hljs-keyword">return</span> rays_o, rays_d<br></code></pre></td></tr></table></figure>
<p>这是因为 OpenCV/Colmap 的相机坐标系里相机的 Up/Y 朝下, 相机光心朝向
+Z 轴，而 NeRF/OpenGL 相机坐标系里相机的 Up/Y 朝上，相机光心朝向 -Z
轴，所以这里代码在方向向量 dir 的第二和第三项乘了个负号。</p>
<figure>
<img src="/archives/27886/RDF_to_RUB.png" alt="RDF to RUB">
<figcaption aria-hidden="true">RDF to RUB</figcaption>
</figure>
<h1 id="参考资料">参考资料</h1>
<ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/593204605/">NeRF代码解读-相机参数与坐标系变换</a></li>
<li><a target="_blank" rel="noopener" href="https://ksimek.github.io/2012/08/13/introduction/">The
Perspective Camera - An Interactive Tour</a></li>
</ul>

      </div>
    </div>
    
      <script src='https://unpkg.com/mermaid@latest/dist/mermaid.min.js'></script>
      <script>
        if (window.mermaid) {
          mermaid.initialize([object Object]);
        }
      </script>
    
  </article>
  <div class="post__foot">
    
      <div class="like-author">
  <input type="checkbox" id="likeCode" />
  <div class="author-face">
    <img height="100px"
         width="100px"
         id="front-face"
         alt="author face"
         src="/assets/reward/avatar.png" />
    <img height="100px"
         width="100px"
         id="back-face"
         alt="like code"
         src="/assets/reward/sponsor.png" />
  </div>
  <div class="like-text">
    给作者倒杯卡布奇诺
  </div>
  <label for="likeCode" class="like-btn">
    <svg viewBox="0 0 1024 1024"
         width="20px"
         style="margin-right: 10px"
         height="20px">
      <path d="M466.88 908.96L113.824 563.296a270.08 270.08 0 0 1 0-387.392c108.8-106.56 284.896-106.56 393.696 0 1.504 1.472 2.976 2.944 4.448 4.48 1.472-1.536 2.944-3.008 4.448-4.48 108.8-106.56 284.896-106.56 393.696 0a269.952 269.952 0 0 1 34.016 347.072l-387.392 385.6a64 64 0 0 1-89.92 0.384z" p-id="13650" fill="#ee4242" />
    </svg>
    喜欢作者
  </label>
</div>

    
    <div class="post-nav">
  
    <div class="post-nav-item-left"></div>
  
  <div class="vhr"></div>
  
    <a class="post-nav-item-right" href="/archives/26715/">
      <div class="text-align">
        <span class="text-small">下一篇</span>
        <svg t="1670570876164"
             class="icon"
             viewBox="0 0 1024 1024"
             transform="scale(-1,-1)"
             width="16"
             height="16">
          <path d="M384 512L731.733333 202.666667c17.066667-14.933333 19.2-42.666667 4.266667-59.733334-14.933333-17.066667-42.666667-19.2-59.733333-4.266666l-384 341.333333c-10.666667 8.533333-14.933333 19.2-14.933334 32s4.266667 23.466667 14.933334 32l384 341.333333c8.533333 6.4 19.2 10.666667 27.733333 10.666667 12.8 0 23.466667-4.266667 32-14.933333 14.933333-17.066667 14.933333-44.8-4.266667-59.733334L384 512z" p-id="14596"/>
        </svg>
      </div>
      常微分方程
    </a>
  
</div>

    
      <div class="related-post">
  <div class="related__head">
    
  
    <a href="/tags/CV/" class="post-tag">#CV</a>
  


  </div>
  <div class="realated__body">
    
      <div class="null"><div class="null-item"><div class="null-title"><a href="\archives\2070\" title="图像评价指标" rel="bookmark">图像评价指标</a></div></div><div class="null-item"><div class="null-title"><a href="\archives\24050\" title="Base64编码" rel="bookmark">Base64编码</a></div></div><div class="null-item"><div class="null-title"><a href="\archives\40010\" title="ClimateNeRF环境配置" rel="bookmark">ClimateNeRF环境配置</a></div></div></div>
    
  </div>
</div>

    
    
      <div id="gitalk-container"></div>
    
  </div>

    </div>
    <div class="foot">
      <div class="foot-inner">
        <div class="foot__head">
          
            <div class="foot-line">
              
                <div class="matts">海</div>
              
                <div class="matts">内</div>
              
                <div class="matts">存</div>
              
                <div class="matts">知</div>
              
                <div class="matts">己</div>
              
            </div>
          
            <div class="foot-line">
              
                <div class="matts">天</div>
              
                <div class="matts">涯</div>
              
                <div class="matts">若</div>
              
                <div class="matts">比</div>
              
                <div class="matts">邻</div>
              
            </div>
          
        </div>
        <div class="foot__body">
          
            <div class="foot-item">
              <div class="foot-item__head">友链</div>
              <div class="foot-item__body">
                
                  <div class="text">
                    <img alt="link" height="20px" width="20px" src="/assets/icon/icon-link.svg"/>
                    <a class="foot-link" target="_blank" rel="noopener" href="https://shennoter.top/">Shennoter</a>
                  </div>
                
                  <div class="text">
                    <img alt="link" height="20px" width="20px" src="/assets/icon/icon-link.svg"/>
                    <a class="foot-link" href="">Jobove</a>
                  </div>
                
              </div>
            </div>
          
          
            <div class="foot-item">
              <div class="foot-item__head">账号</div>
              <div class="foot-item__body">
                
                  <div class="text">
                    <img alt="link" height="20px" width="20px" src="/assets/logo/logo-github.svg"/>
                    <a class="foot-link" target="_blank" rel="noopener" href="https://github.com/Lynchrocket">Lynchrocket</a>
                  </div>
                
                  <div class="text">
                    <img alt="link" height="20px" width="20px" src="/assets/logo/logo-zh.svg"/>
                    <a class="foot-link" target="_blank" rel="noopener" href="https://www.zhihu.com/people/lynchrocket">Lynchrocket</a>
                  </div>
                
              </div>
            </div>
          
          <div class="foot-item">
            <div class="foot-item__head">联系</div>
            <div class="foot-item__body">
              <div class="text">
                <img alt="link" height="20px" width="20px" src="/assets/icon/icon-email.svg"/>
                <a class="foot-link" href="mailto:lynchrocket@gmail.com">lynchrocket@gmail.com</a>
              </div>
            </div>
          </div>
          
          <div class="foot-item">
            <div class="foot-item__head">访客</div>
            <div class="foot-item__body">
              <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
              <span id="busuanzi_container_site_uv">本站总访问量：<span id="busuanzi_value_site_uv"></span>次</span>
            </div>
          </div>
          
        </div>
        <div class="copyright">
          <a href="https://lynchrocket.github.io">C'est la vie</a> &nbsp;|
          &nbsp;Powered by &nbsp;<a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>&nbsp; &
          &nbsp;<a target="_blank" rel="noopener" href="https://github.com/Lynchrocket/hexo-theme-senerity">Senerity</a>&nbsp;
        </div>
      </div>
    </div>
    
      <script src="https://unpkg.com/js-polyfills@0.1.43/es6.js"></script>
      <script id="MathJax-script"
              async
              src="https://www.unpkg.com/mathjax@3.2.2/es5/tex-mml-chtml.js"></script>
    
    
      <script src="/js/search.js"></script>
      <script>searchInitialize("/search.json")</script>
    
    
      <script src="/js/copy-code.js"></script>
    
    
  
    <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
<script type="text/javascript">
  const param = JSON.parse('{"enable":true,"owner":"Lynchrocket","admin":"Lynchrocket","repo":"Lynchrocket.github.io","clientID":"45d8817d291626df7894","clientSecret":"2761427f37f733d92cc64be2e2a3826cc8454cf3","distractionFreeMode":false,"proxy":"https://worker-lingering-hat-47a4.lynchrocket.workers.dev/?https://github.com/login/oauth/access_token","language":"zh-CN","per_page":20}')
  param.id = location.pathname
  const gitalk = new Gitalk(param)
  gitalk.render('gitalk-container')
</script>

  

  </body>
</html>